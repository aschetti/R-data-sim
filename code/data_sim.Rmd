---
title: "Simulate data in R with package `faux`"
author: '[Antonio Schettino](https://antonio-schettino.com/ "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: show
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r doc-setup, include = FALSE}

# ### install packages
# install.packages("here")
# install.packages("knitr")
# install.packages("kableExtra")
# install.packages("tidyverse")
# install.packages("faux")
# install.packages("rstatix")
# install.packages("ggpubr")

### load packages
library(here)
library(knitr)
library(kableExtra)
library(tidyverse)
library(faux)
library(rstatix)
library(ggpubr)

# for RMarkdown
options(digits = 2) # number of decimal digits
opts_chunk$set(
  echo = TRUE, # show code
  warning = FALSE, # no package warnings
  message = FALSE, # no package messages
  fig.dim = c(8, 8) # figure width & height
)

# custom kable
kable_custom <- function(data) {
  knitr::kable(data, digits = getOption("digits")) %>% 
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
}

```

***
***

# Why simulate data?

Here are some reasons[^1]:

- analyze your experimental design
  - number of groups?
  - number of participants?
  - number of conditions?
  - number of trials for each condition?
- evaluate your statistical procedures
  - what are the distributional properties of the data?
  - are model assumptions appropriate?
- power analysis
  - what effect size is your experimental design sensitive to?
  - how does sensitivity change as a function of the number of participants and/or trials?
- plan data management
  - size and type of data and model files
  - folder structure
- practical feasibility
  - is there enough information in the literature to simulate plausible scenarios?
  - is your statistical model computationally feasible?
  - if the results of the power analysis require a large number of participants and/or trials, do you have enough time and/or resources?

# Preparation

In preparation for this workshop, you should have installed on your computer:

- [R](https://cran.r-project.org/)
- [Rstudio](https://rstudio.com/products/rstudio/download/)
- R packages:
  - [`here`](https://github.com/r-lib/here), which easily builds folder paths to load and save files
  - [`knitr`](https://github.com/yihui/knitr) and [`kableExtra`](https://github.com/haozhu233/kableExtra), to format the dynamically generated document
  - [`tidyverse`](https://github.com/tidyverse/tidyverse) and [`ggpubr`](https://github.com/kassambara/ggpubr), for data wrangling and plots
  - [`faux`](https://github.com/debruine/faux/), to simulate the data and create plots
  - [`rstatix`](https://github.com/kassambara/rstatix) for statistical analysis

```{r install-load-pkgs, eval = FALSE}

### install packages
install.packages("here")
install.packages("knitr")
install.packages("kableExtra")
install.packages("tidyverse")
install.packages("faux")
install.packages("rstatix")
install.packages("ggpubr")

### load packages
library(here)
library(knitr)
library(kableExtra)
library(tidyverse)
library(faux)
library(rstatix)
library(ggpubr)

```

Let's also create a custom `ggplot` theme for our graphs:

```{r ggplot-theme}

theme_custom <-
  theme_pubr(base_size = 16) + # base theme from package 'ggpubr'
  theme(
    strip.text = element_text(
      hjust = .5,
      size = 20
    ),
    plot.title = element_text(size = 26, hjust = .5),
    legend.box.background = element_rect(color = "transparent"),
    legend.position = "none"
  )

```

Finally, we need to set the seed for the random number generator. This is very important, because we want to be able to exactly reproduce the data we simulate.

```{r seed-rng}

seed_workshop <- 17
set.seed(seed_workshop)

```

Now that our set up is complete, let's start.

# How to simulate data in R

There are several ways to simulate data in R. One way is to use base R functions. Here we use `rnorm` to generate 1000 random samples from a normal distribution with $\mu$ = 0 and $\sigma$ = 1:

```{r rnorm-data}

rnorm_data <- rnorm(1000, mean = 0, sd = 1)

```

Let's look at the first 10 samples:

```{r rnorm-show}

rnorm_data %>% 
  head(10) %>%
  kable_custom() # create a fancy table using packages 'kable' and 'kableExtra' (here is a custom function)

```

Let's plot the simulated data. We expect a bell-shaped distribution with the majority of generated samples clustered around 0 (because `mean = 0`), although a few samples can still be larger or smaller than the mean.

```{r rnorm-plot}

rnorm_data %>%
  as_tibble() %>%
  ggviolin( # from package 'ggpubr'
    y = "value", # dependent variable
    color = "#00AFBB", # density: line color
    size = 1, # density: line width
    fill = "#00AFBB", # density: fill color
    alpha = .5, # density: fill color transparency
    linetype = "solid", # density: line type
    trim = TRUE, # density: trim tails
    width = 1, # density: violin width
    add = c("boxplot", "jitter"), # overlay boxplot and jittered individual data points
    add.params = list(
      color = "black", # boxplot and jittered points: color
      fill = "white", # boxplot and jittered points: fill color
      alpha = .2 # boxplot and jittered points: fill transparency
    ),
    title = "Normal distribution", # plot title
    xlab = "", # x-axis: title 
    label.rectangle = TRUE, # rectangle underneath text
    ggtheme = theme_custom # ggplot theme
  )

```

Other functions allow you to sample from different distributions, e.g., uniform (`runif`), binomial (`rbinom`), Student's t (`rt`), and more (for a complete list, type `?distributions` in the console).

However, in this workshop we will be using the package `faux`, created by [Prof. Lisa DeBruine](https://www.gla.ac.uk/researchinstitutes/neurosciencepsychology/staff/lisadebruine/). Despite being quite recent, this package is actively maintained and well-documented, and its framework is user-friendly and adaptable to several popular study designs in the social sciences[^2].

## One-sample t-test

Imagine we plan to ask a group of 50 participants to complete an online test. We assume the test scores to follow a normal distribution with $\mu$ = 2 and $\sigma$ = 1. First, let's create the variables that represent this *a priori* information:

```{r ttest-onesample-params}

ttest_onesample_label <- list(condition = c("test")) # condition name and levels
ttest_onesample_n <- 50 # number of participants
ttest_onesample_mu_cond <- 2 # mean
ttest_onesample_sd_cond <- 1 # standard deviation

```

Now we have all the parameters we need to generate (hypothetical) scores of this test from a normal distribution with the parameters specified above. The relevant function in the `faux` package is `sim_design`:

```{r ttest-onesample-data}

ttest_onesample_data <-
  sim_design(
    between = ttest_onesample_label, # the data come from one independent group, hence "between-subject"
    n = ttest_onesample_n, # number of participants
    mu = ttest_onesample_mu_cond, # mean
    sd = ttest_onesample_sd_cond, # standard deviation
    empirical = FALSE, # exact mean/SD?
    long = TRUE, # results in long format?
    dv = list(value = "value"), # name of dependent variables
    id = list(id = "id"), # name of ID column
    plot = FALSE, # plot?
    rep = 1 # number of simulated datasets
  ) %>%
  as_tibble()

```

Let's look at the first 10 rows of the simulated dataset:

```{r ttest-onesample-data-show}

ttest_onesample_data %>%
  head(n = 10) %>%
  kable_custom()

```

Save the data as *.csv* file:

```{r ttest-onesample-data-save}

write_csv(
  ttest_onesample_data,
  here("data", "ttest_onesample_data.csv")
)

```

Plot using the `plot_design` function in `faux`:

```{r ttest-onesample-plot}

ttest_onesample_plot <-
  ttest_onesample_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("One-sample t-test") +
  theme_custom

ttest_onesample_plot

```

Save the plot as *.png* file:

```{r ttest-onesample-plot-save}

ggsave(
  filename = "ttest_onesample_plot.png",
  plot = ttest_onesample_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

How can we be sure that `faux` correctly sampled from a normal distribution with $\mu$ = 2 and $\sigma$ = 1? The mean and standard deviation of the simulated dataset should be close to what we imputed. They would not be *exactly* the same (because of the probabilistic nature of the sampling), unless you set `empirical = FALSE` when using `sim_design`. Let's verify:

```{r ttest-onesample-param-recovery}

ttest_onesample_param_recovery <-
  ttest_onesample_data %>%
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  mutate(
    n_imputed = ttest_onesample_n,
    mean_imputed = ttest_onesample_mu_cond,
    sd_imputed = ttest_onesample_sd_cond
    ) %>% 
  select(n, n_imputed, mean, mean_imputed, sd, sd_imputed)

ttest_onesample_param_recovery %>%
  kable_custom()

```

It seems that `faux` did its job well: the mean of the simulated dataset is `r ttest_onesample_param_recovery$mean` and its standard deviation is `r ttest_onesample_param_recovery$sd`[^3].

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically larger than 0. We can test this hypothesis in several ways, but we keep it simple and run a one-tailed one-sample Student's t-test against $\mu$ = 0 using the `t_test` function from the package `rstatix`:

```{r ttest-onesample-test}

ttest_onesample_results <-
  t_test(
    data = ttest_onesample_data, # data
    formula = value ~ 1, # formula
    p.adjust.method = "holm", # p-value adjustment
    paired = FALSE, # paired test?
    var.equal = TRUE, # assume equal variance? if FALSE, it's a Welch's test
    alternative = "greater", # alternative hypothesis (either larger or smaller, larger, or smaller than mu)
    mu = 0, # null value
    conf.level = .95, # width confidence intervals
    detailed = FALSE
  ) %>% 
  select(-.y.)

# see the results
ttest_onesample_results %>%
  kable_custom()

```

Results indicate that the mean test score is significantly larger than 0: *t*(`r ttest_onesample_results$df`) = `r format(ttest_onesample_results$statistic, digits = 3)`, *p* = `r format(ttest_onesample_results$p, digits = 3)`.

## Between-subject t-test

Imagine we wish to study the effect of a specific drug vs. placebo on the test scores above. We recruit a total of 90 participants: 40 will be administered the drug, and 50 the placebo. We assume the test scores to follow:

- a normal distribution with $\mu$ = 1 and $\sigma$ = 1 in the **placebo** group
- a normal distribution with $\mu$ = 2 and $\sigma$ = 1.4 in the **drug** group

Let's create the variables that represent this *a priori* information. `faux` works with lists, which means that, for each parameter, we will need to create one list per group: 

```{r ttest-between-params}

ttest_between_label <- list(treatment = c("placebo", "drug")) # treatment labels
ttest_between_n <- list(placebo = 50, drug = 40) # number of observations per group
ttest_between_mu_cond <- list(placebo = 1, drug = 2) # means per group
ttest_between_sd_cond <- list(placebo = 1, drug = 1.4) # standard deviations per group

```

Simulate data using `sim_design`:

```{r ttest-between-data}

ttest_between_data <-
  sim_design(
    between = ttest_between_label,
    n = ttest_between_n,
    mu = ttest_between_mu_cond,
    sd = ttest_between_sd_cond,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ttest-between-data-show}

ttest_between_data %>%
  head(n = 10) %>%
  kable_custom()

```

Save the data as *.csv* file:

```{r ttest-between-data-save}

write_csv(
  ttest_between_data,
  here("data", "ttest_between_data.csv")
)

```

Plot using the `plot_design` function in `faux`:

```{r ttest-between-plot}

ttest_between_plot <-
  ttest_between_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Between-subject t-test") +
  theme_custom

ttest_between_plot

```

Save the plot as *.png* file:

```{r ttest-between-plot-save}

ggsave(
  filename = "ttest_between_plot.png",
  plot = ttest_between_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the two normal distributions indicated above:

```{r ttest-between-param-recovery}

ttest_between_param_recovery <-
  ttest_between_data %>%
  group_by(treatment) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    n_imputed = map_chr(ttest_between_n, toString),
    mean_imputed = map_chr(ttest_between_mu_cond, toString),
    sd_imputed = map_chr(ttest_between_sd_cond, toString)
  ) %>% 
  select(treatment, n, n_imputed, mean, mean_imputed, sd, sd_imputed)

ttest_between_param_recovery %>%
  kable_custom()

```

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically smaller in the `placebo` compared to the `drug` condition. Let's run a one-tailed independent-sample Student's t-test using the `t_test` function:

```{r ttest-between-test}

ttest_between_results <-
  t_test(
    data = ttest_between_data,
    formula = value ~ treatment,
    p.adjust.method = "holm",
    paired = FALSE,
    var.equal = TRUE,
    alternative = "less",
    mu = 0,
    conf.level = .95,
    detailed = FALSE
  ) %>% 
  select(-.y.)

ttest_between_results %>%
  kable_custom()

```

Results indicate that the mean test score is significantly smaller in the `placebo` compared to the `drug` condition: *t*(`r format(ttest_between_results$df, digits = 4)`) = `r format(ttest_between_results$statistic, digits = 3)`, *p* = `r format(ttest_between_results$p, digits = 3)`.

## Within-subject t-test

Imagine we show to one group of participants emotional or neutral pictures before the online test. All participants (in this case, N = 50) are presented with all pictures, so this is a within-subject design. We assume the test scores to follow:

- a normal distribution with $\mu$ = 1.3 and $\sigma$ = 1.2 in the **neutral** condition
- a normal distribution with $\mu$ = 2.1 and $\sigma$ = 1.6 in the **emotion** condition

Create the variables:

```{r ttest-within-params}

ttest_within_within <- list(condition = c("neutral", "emotion")) # list of within-subject factors
ttest_within_n <- list(neutral = 50, emotion = 50) # number of participants must be the same for each condition
ttest_within_mu_cond <- list(neutral = 1.3, emotion = 2.1)
ttest_within_sd_cond <- list(neutral = 1.2, emotion = 1.6)
ttest_within_r <- .7 # correlations among variables

```

Simulate data:

```{r ttest-within-data}

ttest_within_data <-
  sim_design(
    within = ttest_within_within,
    n = ttest_within_n,
    mu = ttest_within_mu_cond,
    sd = ttest_within_sd_cond,
    r = ttest_within_r,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ttest-within-data-show}

ttest_within_data %>%
  head(n = 10) %>%
  kable_custom()

```

Save the data:

```{r ttest-within-data-save}

write_csv(
  ttest_within_data,
  here("data", "ttest_within_data.csv")
)

```

Plot:

```{r ttest-within-plot}

ttest_within_plot <-
  ttest_within_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Within-subject t-test") +
  theme_custom

ttest_within_plot

```

Save the plot:

```{r ttest-within-plot-save}

ggsave(
  filename = "ttest_within_plot.png",
  plot = ttest_within_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the two normal distributions indicated above:

```{r ttest-within-param-recovery}

ttest_within_param_recovery <-
  ttest_within_data %>%
  group_by(condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    n_imputed = map_chr(ttest_within_n, toString),
    mean_imputed = map_chr(ttest_within_mu_cond, toString),
    sd_imputed = map_chr(ttest_within_sd_cond, toString)
  ) %>% 
  select(condition, n, n_imputed, mean, mean_imputed, sd, sd_imputed)

ttest_within_param_recovery %>%
  kable_custom()

```

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically smaller after exposure to the neutral relative to emotional pictures. Let's run a one-tailed paired-sample Student's t-test:

```{r ttest-within-test}

ttest_within_results <-
  t_test(
    data = ttest_within_data,
    formula = value ~ condition,
    p.adjust.method = "holm",
    paired = TRUE,
    var.equal = TRUE,
    alternative = "less",
    mu = 0,
    conf.level = .95,
    detailed = FALSE
  ) %>% 
  select(-.y.)

ttest_within_results %>%
  kable_custom()

```

Results indicate that the mean test score is significantly smaller in the `neutral` compared to the `emotional` condition: *t*(`r format(ttest_within_results$df, digits = 4)`) = `r format(ttest_within_results$statistic, digits = 3)`, *p* = `r format(ttest_within_results$p, digits = 3)`.

## 2 x 3 mixed ANOVA

Now our hypothetical design gets a bit more complicated. Imagine that, before the online test, we show to participants 50 neutral, 50 pleasant, and 50 unpleasant pictures. Participants are randomly assigned to two groups: one will be administered a drug (N = 30), the other a placebo (N = 40). This is a mixed design. We assume the test scores to follow:

* `control` group:
  - `neutral` condition: normal distribution with $\mu$ = 1 and $\sigma$ = 1
  - `unpleasant` condition: normal distribution with $\mu$ = 1.5 and $\sigma$ = 1.2
  - `pleasant` condition: normal distribution with $\mu$ = 1.4 and $\sigma$ = 1.2
* `drug` group:
  - `neutral` condition: normal distribution with $\mu$ = 1.1 and $\sigma$ = 1.2
  - `unpleasant` condition: normal distribution with $\mu$ = 1.4 and $\sigma$ = 1.5
  - `pleasant` condition: normal distribution with $\mu$ = 2.1 and $\sigma$ = 1.6

Create the variables:

```{r ANOVA-params}

ANOVA_within <- list(condition = c("neutral", "unpleasant", "pleasant"))
ANOVA_between <- list(treatment = c("control", "drug"))
ANOVA_n <- list(
  control = c(neutral = 40, unpleasant = 40, pleasant = 40), # number of participants must be the same for each condition...
  drug = c(neutral = 30, unpleasant = 30, pleasant = 30) # ... but can be different between groups
)
ANOVA_mu_cond <- list(
  control = c(neutral = 1, unpleasant = 1.5, pleasant = 1.4),
  drug = c(neutral = 1.1, unpleasant = 1.4, pleasant = 2.1)
)
ANOVA_sd_cond <- list(
  control = c(neutral = 1, unpleasant = 1.2, pleasant = 1.2),
  drug = c(neutral = 1.2, unpleasant = 1.5, pleasant = 1.6)
)
# if the design has more than 2 within-subject conditions, specify each correlation in the upper right triangle of the correlation matrix as a vector (https://debruine.github.io/faux/articles/sim_design.html#correlations-1)
ANOVA_r <- list(
  control = c(
    .40, .50,
    .60
  ),
  drug = c(
    .15, .25,
    .45
  )
)

```

Simulate data:

```{r ANOVA-data}

ANOVA_data <-
  sim_design(
    within = ANOVA_within,
    between = ANOVA_between,
    n = ANOVA_n,
    mu = ANOVA_mu_cond,
    sd = ANOVA_sd_cond,
    r = ANOVA_r,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ANOVA-data-show}

ANOVA_data %>%
  head(n = 10) %>%
  kable_custom()

```

Save the data:

```{r ANOVA-data-save}

write_csv(
  ANOVA_data,
  here("data/ANOVA_data.csv")
)

```

Plot:

```{r ANOVA-plot}

ANOVA_plot <-
  ANOVA_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Mixed ANOVA") +
  theme_custom +
  theme(legend.position = "right")

ANOVA_plot

```

Save the plot:

```{r ANOVA-plot-save}

ggsave(
  filename = "ANOVA_plot.png",
  plot = ANOVA_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the normal distributions indicated above:

```{r ANOVA-param-recovery}

ANOVA_param_recovery <-
  ANOVA_data %>%
  group_by(treatment, condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    n_imputed = c(map_chr(ANOVA_n$control, toString), map_chr(ANOVA_n$drug, toString)),
    mean_imputed = c(map_chr(ANOVA_mu_cond$control, toString), map_chr(ANOVA_mu_cond$drug, toString)),
    sd_imputed = c(map_chr(ANOVA_sd_cond$control, toString), map_chr(ANOVA_sd_cond$drug, toString))
  ) %>% 
  select(condition, n, n_imputed, mean, mean_imputed, sd, sd_imputed)

ANOVA_param_recovery %>%
  kable_custom()

```

### Statistical Analysis

Let's run a mixed ANOVA on the simulated data. First, the omnibus test:

```{r ANOVA-test-omnibus}

ANOVA_omnibus <-
  anova_test(
    data = ANOVA_data,
    dv = value,
    wid = id,
    between = "treatment",
    within = "condition",
    type = 2,
    effect.size = "ges",
    detailed = FALSE
  ) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "holm")

ANOVA_omnibus %>% 
  kable_custom()

```

Results show a statistically significant main effect of `condition` (*F*(`r format(ANOVA_omnibus$DFn[2])`, `r format(ANOVA_omnibus$DFd[2])`) = `r format(ANOVA_omnibus$F[2])`, *p* = `r format(ANOVA_omnibus$p.adj[2])`, $\eta_{G}^{2}$ = `r format(ANOVA_omnibus$ges[2], digits = 3)`) and `treatment` x `condition` (*F*(`r format(ANOVA_omnibus$DFn[3])`, `r format(ANOVA_omnibus$DFd[3])`) = `r format(ANOVA_omnibus$F[3])`, *p* = `r format(ANOVA_omnibus$p.adj[3])`, $\eta_{G}^{2}$ = `r format(ANOVA_omnibus$ges[3], digits = 3)`).

```{r ANOVA-test-treatment}

ANOVA_pairwise_treatment <-
  ANOVA_data %>%
  group_by(condition) %>%
  t_test(
    formula = value ~ treatment,
    p.adjust.method = "holm",
    paired = FALSE,
    var.equal = TRUE,
    alternative = "two.sided",
    mu = 0,
    conf.level = 0.95
  ) %>% 
  select(condition, group1, group2, n1, n2, t = statistic, df, p)

ANOVA_pairwise_treatment %>%
  kable_custom()

```

Pairwise comparisons suggest that test scores in the `control` group are statistically smaller than in the `drug` group only in the `pleasant` condition: *t*(`r format(ANOVA_pairwise_treatment$df[3])`) = `r format(ANOVA_pairwise_treatment$statistic[3])`, *p* = `r format(ANOVA_pairwise_treatment$p[3])`.

```{r ANOVA-test-condition}

ANOVA_pairwise_condition <-
  ANOVA_data %>%
  group_by(treatment) %>%
  t_test(
    formula = value ~ condition,
    p.adjust.method = "holm",
    paired = TRUE,
    var.equal = TRUE,
    alternative = "two.sided",
    mu = 0,
    conf.level = 0.95
  ) %>% 
  select(treatment, group1, group2, n1, n2, t = statistic, df, p.holm = p.adj)

ANOVA_pairwise_condition %>%
  kable_custom()

```

Within each group, differences among `condition` levels are only observed in the `drug` group, with statistically smaller scores in the `neutral` compared to the `pleasant` condition: *t*(`r format(ANOVA_pairwise_condition$df[5])`) = `r format(ANOVA_pairwise_condition$statistic[5], digits = 3)`, *p* = `r format(ANOVA_pairwise_condition$p[5])`.

# Generate data from existing dataset

Throughout the workshop we have imputed specific means and standard deviations, as well as correlations among within-subject variables. In real-life situations, finding these numbers may not be easy. It is possible to extract these parameters from tables in papers or directly from other datasets, e.g., published by other researchers or collected in previous studies[^4]. 

Thankfully, `faux` allows to simulate data similar to an already existing dataset. Let's try and simulate a dataset similar to what we generated for our within-subject t-test example. First, we load the original data:

```{r synth-load-ttest-within-data}

original_ttest_within_data <- 
  read_csv(
  here("data", "ttest_within_data.csv"),
  col_names = TRUE, # keep column names
  col_types = list(col_factor(), col_factor(), col_double()) # coerce columns 1 and 2 to factors, column 3 to numeric
)

```

Then we use the function `sim_df` to generate a synthetic dataset from the original data:

```{r synth-gen-ttest-within-data}

synth_ttest_within_data <- 
  sim_df(
    original_ttest_within_data,
    n = 50, # number of samples per group (can also be different from the original dataset)
    within = "condition", # within-subject columns
    between = c(), # between-subject columns (in this example, none)
    id = "id", # name of ID column
    dv = "value", # name of dependent variable column
    empirical = FALSE # exact mean/SD?
  ) %>% 
  pivot_longer(neutral:emotion, names_to = "condition", values_to = "value") %>%
  as_tibble()

```

Look at the first 10 rows of the synthetic dataset:

```{r synth-ttest-within-data-show}

synth_ttest_within_data %>%
  head(n = 10) %>%
  kable_custom()

```

Save the data:

```{r synth-ttest-within-data-save}

write_csv(
  synth_ttest_within_data,
  here("data", "synth_ttest_within_data.csv")
)

```

Plot:

```{r synth-ttest-within-plot}

synth_ttest_within_plot <- 
  synth_ttest_within_data %>%
  ggviolin(
    y = "value",
    x = "condition",
    color = "black",
    size = 1,
    fill = "condition",
    alpha = .5,
    linetype = "solid",
    trim = TRUE,
    width = 1,
    add = c("boxplot", "jitter"),
    add.params = list(
      color = "black",
      fill = "white",
      alpha = .5
    ),
    title = "Synthetic data",
    xlab = "",
    label.rectangle = TRUE,
    ggtheme = theme_custom
  )

synth_ttest_within_plot

```

Save the plot:

```{r synth-ttest-within-plot-save}

ggsave(
  filename = "synth_ttest_within_plot.png",
  plot = synth_ttest_within_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

Recover the parameters: 

```{r synth-ttest-within-param-recovery}

original_ttest_within_param_recovery <-
  original_ttest_within_data %>%
  group_by(condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(data = "original", .before = condition)

synth_ttest_within_param_recovery <-
  synth_ttest_within_data %>%
  group_by(condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(data = "synthetic", .before = condition)

compare_original_synth_ttest_within <-
  full_join(original_ttest_within_param_recovery, synth_ttest_within_param_recovery) %>% 
  arrange(condition) %>% 
  select(-variable)

compare_original_synth_ttest_within %>% 
  kable_custom()

```

Yes, `faux` did a good job.





# Limitations

`faux` only generates samples from normal distributions. For more complex datasets, a very flexible option is the R package [`synthpop`](https://cran.r-project.org/web/packages/synthpop/index.html).









problems usually arise when hypothesizing not only means and standard deviations, but especially correlations among variables in within-subject designs


It is possible to extract these parameters from tables in papers or other datasets, e.g., published by other researchers or collected in previous studies. Please note that data from small-scale pilot studies are not reliable and should not be used to estimate such parameters[^3].




## ADVANCED: Simulate data with crossed random factors

Until now we have generated, for each participant, mean values for each condition. However, in real-life experiments we typically present participants with a number of trials per condition (and only later on we calculate the mean of these trial-level values). 

The `faux` package allows to simulate data with crossed random factors







# Conclusion



# Session Info

```{r session-info}

sessionInfo()

```

***
***

[^1]: Adapted from the book [**Answering questions with data**](https://crumplab.github.io/statistics/index.html) (Chapter [11](https://crumplab.github.io/statistics/simulating-data.html#reasons-to-simulate)) by Matthew J. C. Crump.
[^2]: There are many other R packages that allow data simulation, for example [`simstudy`](https://github.com/kgoldfeld/simstudy), [`simr`](https://github.com/pitakakariki/simr), [`simulator`](https://github.com/jacobbien/simulator), [`lsasim`](https://github.com/tmatta/lsasim), [`simmer`](https://github.com/r-simmer/simmer/), and [`parSim`](https://github.com/SachaEpskamp/parSim).
[^3]: Explore the function `get_summary_stats` from package `rstatix`, especially the argument `type`... it's very comprehensive.
[^4]: Please note that data from small-scale pilot studies are not reliable and should not be used to estimate such parameters. For a discussion of this issue regarding effect size estimation for statistical power analysis, see [this paper](https://doi.org/10.1016/j.jesp.2017.09.004) by Casper Albers and Daniël Lakens.
