---
title: "Simulate data in R with package `faux`"
author: '[Antonio Schettino](https://osf.io/zbv65/ "Antonio Schettino")'
date: '`r Sys.Date()`'
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: show
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r doc-setup, include = FALSE}

seed_smorfia <- 17 # 'A disgrazia!
set.seed(seed_smorfia) # set RNG seed

# ### install packages
# install.packages("here")
# install.packages("knitr")
# install.packages("kableExtra")
# install.packages("tidyverse")
# install.packages("faux")
# install.packages("rstatix")
# install.packages("lme4")
# install.packages("broom.mixed")
# install.packages("ggpubr")

### load packages
library(here)
library(knitr)
library(kableExtra)
library(tidyverse)
library(faux)
library(rstatix)
library(lme4)
library(broom.mixed)
library(ggpubr)

# for RMarkdown
# options(digits = 2) # number of decimal digits
opts_chunk$set(
  echo = TRUE, # show code
  warning = FALSE, # no package warnings
  message = FALSE, # no package messages
  fig.dim = c(8, 8) # figure width & height
)

```

***
***

# Why simulate data?

Here are some reasons[^1]:

- analyze your experimental design
  - number of groups?
  - number of participants?
  - number of conditions?
  - number of trials for each condition?
- evaluate your statistical procedures
  - what are the distributional properties of the data?
  - are model assumptions appropriate?
- power analysis
  - what effect size is your experimental design sensitive to?
  - how does sensitivity change as a function of the number of participants and/or trials?
- plan data management
  - size and type of data and model files
  - folder structure
- practical feasibility
  - is there enough information in the literature to simulate plausible scenarios?
  - is your statistical model computationally feasible?
  - if the results of the power analysis require a large number of participants and/or trials, do you have enough time and/or resources?

# Preparation

In preparation for this meeting, you should have installed on your computer:

- [R](https://cran.r-project.org/)
- [Rstudio](https://rstudio.com/products/rstudio/download/)
- R packages:
  - [`here`](https://github.com/r-lib/here), which easily builds folder paths to load and save files
  - [`knitr`](https://github.com/yihui/knitr) and [`kableExtra`](https://github.com/haozhu233/kableExtra), to format the dynamically generated document
  - [`tidyverse`](https://github.com/tidyverse/tidyverse) and [`ggpubr`](https://github.com/kassambara/ggpubr), for data wrangling and plots
  - [`faux`](https://github.com/debruine/faux/), to simulate the data
  - [`rstatix`](https://github.com/kassambara/rstatix) and [`lme4`](https://github.com/lme4/lme4), for statistical analysis
  - [`broom.mixed`](https://github.com/bbolker/broom.mixed), for easier extraction of the results of the multilevel model

```{r install-load-pkgs, eval = FALSE}

### install packages
install.packages("here")
install.packages("knitr")
install.packages("kableExtra")
install.packages("tidyverse")
install.packages("faux")
install.packages("rstatix")
install.packages("lme4")
install.packages("broom.mixed")
install.packages("ggpubr")

### load packages
library(here)
library(knitr)
library(kableExtra)
library(tidyverse)
library(faux)
library(rstatix)
library(lme4)
library(broom.mixed)
library(ggpubr)

```

Let's also create a custom `ggplot` theme for our graphs:

```{r ggplot-theme}

theme_custom <-
  theme_pubr(base_size = 16) + # base theme from package 'ggpubr'
  theme(
    strip.text = element_text(
      hjust = .5,
      size = 20
    ),
    plot.title = element_text(size = 26, hjust = .5),
    legend.box.background = element_rect(color = "transparent"),
    legend.position = "none"
  )

```

Last but not least, we need to set the seed for the random number generator. This is very important, because we want to be able to exactly reproduce the data we simulate.

```{r seed-rng, eval = FALSE}

seed_smorfia <- 17
set.seed(seed_smorfia)

```

Now that we have everything, let's start.

# How to simulate data in R

There are several ways to simulate data in R. One way is to use base R functions. Here we use `rnorm` to generate 1000 random samples from a normal distribution with $\mu$ = 0 and $\sigma$ = 1:

```{r rnorm-data}

rnorm_data <- rnorm(1000, mean = 0, sd = 1)

```

Let's look at the first 10 samples:

```{r rnorm-show}

rnorm_data %>% 
  head(10) %>%
  kable() %>% # create a fancy table
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # make it even fancier, thanks to package 'kableExtra'

```

Let's plot the simulated data. We expect a bell-shaped distribution with the majority of generated samples clustered around 0 (because `mean = 0`), although a few samples can still be larger or smaller than the mean.

```{r rnorm-plot}

rnorm_data %>%
  as_tibble() %>%
  ggviolin( # from package 'ggpubr'
    y = "value", # dependent variable
    color = "#00AFBB", # density: line color
    size = 1, # density: line width
    fill = "#00AFBB", # density: fill color
    alpha = .5, # density: fill color transparency
    linetype = "solid", # density: line type
    trim = TRUE, # density: trim tails
    width = 1, # density: violin width
    add = c("boxplot", "jitter"), # overlay boxplot and jittered individual data points
    add.params = list(
      color = "black", # boxplot and jittered points: color
      fill = "white",# boxplot and jittered points: fill color
      alpha = .2# boxplot and jittered points: fill transparency
    ),
    title = "Normal distribution", # plot title
    xlab = "", # x-axis: title 
    label.rectangle = TRUE, # rectangle underneath text
    ggtheme = theme_custom # ggplot theme
  )

```

Other functions allow you to sample from different distributions, e.g., uniform (`runif`), binomial (`rbinom`), Student's t (`rt`), and more (for a complete list, type `?distributions` in the console).

However, in this workshop we will be using the package `faux`, created by [Prof. Lisa DeBruine](https://www.gla.ac.uk/researchinstitutes/neurosciencepsychology/staff/lisadebruine/). Despite being quite recent, this package is actively maintained and well-documented, and its framework is user-friendly and adaptable to several popular study designs in the social sciences.

The first study design we will simulate is a one-sample t-test.

## One-sample t-test

Imagine we plan to ask a group of 50 participants to complete an online test. Based on published literature and/or our own data collected as part of previous projects, we expect the test scores to follow a normal distribution with $\mu$ = 2 and $\sigma$ = 1. First, let's create the variables that represent this *a priori* information:

```{r ttest-onesample-params}

ttest_onesample_label <- list(condition = c("test")) # condition name
ttest_onesample_n <- 50 # number of participants
ttest_onesample_mu_cond <- 2 # mean
ttest_onesample_sd_cond <- 1 # standard deviation

```

Now we have all the parameters we need to generate (hypothetical) scores of this test from a normal distribution with the parameters specified above. The relevant function in the `faux` package is `sim_design`:

```{r ttest-onesample-data}

# data simulation
ttest_onesample_data <-
  sim_design(
    between = ttest_onesample_label, # the data come from one independent group, that's why it's "between-subject"
    n = ttest_onesample_n, # number of participants
    mu = ttest_onesample_mu_cond, # mean
    sd = ttest_onesample_sd_cond, # standard deviation
    empirical = FALSE, # exact mean/SD?
    long = TRUE, # results in long format?
    dv = list(value = "value"), # name of dependent variables
    id = list(id = "id"), # name of ID column
    plot = FALSE, # plot?
    rep = 1 # number of simulated datasets
  ) %>%
  as_tibble()

```

Let's look at the first 10 rows of the simulated dataset:

```{r ttest-onesample-data-show}

ttest_onesample_data %>%
  head(n = 10) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Save the data as *.csv* file:

```{r ttest-onesample-data-save}

write_csv(
  ttest_onesample_data,
  here("data", "ttest_onesample_data.csv")
)

```

Plot using the `plot_design` function in `faux`:

```{r ttest-onesample-plot}

ttest_onesample_plot <-
  ttest_onesample_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("One-sample t-test") +
  theme_custom

ttest_onesample_plot

```

Save the plot as *.png* file:

```{r ttest-onesample-plot-save}

ggsave(
  filename = "ttest_onesample_plot.png",
  plot = ttest_onesample_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

How can we be sure that `faux` correctly sampled from a normal distribution with $\mu$ = 2 and $\sigma$ = 1? The mean and standard deviation of the simulated dataset should be close to what we imputed. They would not be *exactly* the same (because of the probabilistic nature of the sampling), unless you set `empirical = FALSE` when using `sim_design` . Let's verify:

```{r ttest-onesample-param-recovery}

ttest_onesample_param_recovery <-
  ttest_onesample_data %>%
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  mutate(
    mean_imputed = ttest_onesample_mu_cond,
    sd_imputed = ttest_onesample_sd_cond
    ) %>% 
  select(variable, n, mean, mean_imputed, sd, sd_imputed)

ttest_onesample_param_recovery %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

It seems that `faux` did its job well: the mean of the simulated dataset is `r ttest_onesample_param_recovery$mean` and its standard deviation is `r ttest_onesample_param_recovery$sd`[^2].

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically larger than 0. We can test this hypothesis in several ways, but we keep it simple and run a one-tailed one-sample Student's t-test against $\mu$ = 0 using the `t_test` function from the package `rstatix`:

```{r ttest-onesample-test}

ttest_onesample_results <-
  t_test(
    data = ttest_onesample_data, # data
    formula = value ~ 1, # formula
    p.adjust.method = "holm", # p-value adjustment
    paired = FALSE, # paired test?
    var.equal = TRUE, # assume equal variance?
    alternative = "greater", # alternative hypothesis (two-sided, larger than mu, smaller than mu)
    mu = 0, # null value
    conf.level = .95, # width confidence intervals
    detailed = FALSE
  )

# see the results
ttest_onesample_results %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Results indicate that the mean test score is significantly larger than 0: *t*(`r ttest_onesample_results$df`) = `r ttest_onesample_results$statistic`, *p* = `r format(ttest_onesample_results$p, digits = 3)`.

## Between-subject t-test

Imagine we wish to study the effect of a specific drug vs. placebo on the test scores above. We recruit a total of 90 participants: 40 will be administered the drug, and 50 the placebo. Based on published literature and/or our own data collected as part of previous projects, we expect the test scores to follow:

- a normal distribution with $\mu$ = 1 and $\sigma$ = 1 in the **placebo** group
- a normal distribution with $\mu$ = 2 and $\sigma$ = 1.4 in the **drug** group

Let's create the variables that represent this *a priori* information. `faux` works with lists, which means that, for each parameter, we will need to create one list per group: 

```{r ttest-between-params}

ttest_between_label <- list(treatment = c("placebo", "drug")) # condition names
ttest_between_n <- list(placebo = 50, drug = 40) # number of observations per group
ttest_between_mu_cond <- list(placebo = 1, drug = 2) # means per group
ttest_between_sd_cond <- list(placebo = 1, drug = 1.4) # standard deviations per group

```

Simulate data using `sim_design`:

```{r ttest-between-data}

ttest_between_data <-
  sim_design(
    between = ttest_between_label,
    n = ttest_between_n,
    mu = ttest_between_mu_cond,
    sd = ttest_between_sd_cond,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ttest-between-data-show}

ttest_between_data %>%
  head(n = 10) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Save the data as *.csv* file:

```{r ttest-between-data-save}

write_csv(
  ttest_between_data,
  here("data", "ttest_between_data.csv")
)

```

Plot using the `plot_design` function in `faux`:

```{r ttest-between-plot}

ttest_between_plot <-
  ttest_between_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Between-subject t-test") +
  theme_custom

ttest_between_plot

```

Save the plot as *.png* file:

```{r ttest-between-plot-save}

ggsave(
  filename = "ttest_between_plot.png",
  plot = ttest_between_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the two normal distributions indicated above:

```{r ttest-between-param-recovery}

ttest_between_param_recovery <-
  ttest_between_data %>%
  group_by(treatment) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    mean_imputed = map_chr(ttest_between_mu_cond, toString),
    sd_imputed = map_chr(ttest_between_sd_cond, toString)
  ) %>% 
  select(variable, treatment, n, mean, mean_imputed, sd, sd_imputed)

ttest_between_param_recovery %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Looks reasonable.

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically smaller in the `placebo` compared to the `drug` condition. Let's run a one-tailed independent-sample Student's t-test using the `t_test` function:

```{r ttest-between-test}

ttest_between_results <-
  t_test(
    data = ttest_between_data,
    formula = value ~ treatment,
    p.adjust.method = "holm",
    paired = FALSE,
    var.equal = TRUE,
    alternative = "less",
    mu = 0,
    conf.level = .95,
    detailed = FALSE
  )

ttest_between_results %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Results indicate that the mean test score is significantly smaller in the `placebo` compared to the `drug` condition: *t*(`r format(ttest_between_results$df, digits = 4)`) = `r format(ttest_between_results$statistic, digits = 3)`, *p* = `r format(ttest_between_results$p, digits = 3)`.

## Within-subject t-test

Imagine we show to participants emotional or neutral pictures before the online test. All participants (in this case, N = 50) are presented with all pictures, so this is a within-subject design. Based on published literature and/or our own data collected as part of previous projects, we expect the test scores to follow:

- a normal distribution with $\mu$ = 1.3 and $\sigma$ = 1.2 in the **neutral** condition
- a normal distribution with $\mu$ = 2.1 and $\sigma$ = 1.6 in the **emotion** condition

Create the variables:

```{r ttest-within-params}

ttest_within_within <- list(condition = c("neutral", "emotion")) # list of within-subject factors
ttest_within_n <- list(neutral = 50, emotion = 50) # number of participants must be the same for each condition
ttest_within_mu_cond <- list(neutral = 1.3, emotion = 2.1)
ttest_within_sd_cond <- list(neutral = 1.2, emotion = 1.6)
ttest_within_r <- .7 # correlations among variables

```

Simulate data:

```{r ttest-within-data}

ttest_within_data <-
  sim_design(
    within = ttest_within_within,
    n = ttest_within_n,
    mu = ttest_within_mu_cond,
    sd = ttest_within_sd_cond,
    r = ttest_within_r,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ttest-within-data-show}

# show first 10 rows
ttest_within_data %>%
  head(n = 10) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Save the data:

```{r ttest-within-data-save}

write_csv(
  ttest_within_data,
  here("data", "ttest_within_data.csv")
)

```

Plot:

```{r ttest-within-plot}

ttest_within_plot <-
  ttest_within_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Within-subject t-test") +
  theme_custom

ttest_within_plot

```

Save the plot:

```{r ttest-within-plot-save}

ggsave(
  filename = "ttest_within_plot.png",
  plot = ttest_within_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the two normal distributions indicated above:

```{r ttest-within-param-recovery}

ttest_within_param_recovery <-
  ttest_within_data %>%
  group_by(condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    mean_imputed = map_chr(ttest_within_mu_cond, toString),
    sd_imputed = map_chr(ttest_within_sd_cond, toString)
  ) %>% 
  select(variable, condition, n, mean, mean_imputed, sd, sd_imputed)

ttest_within_param_recovery %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Looks ok.

### Statistical Analysis

Our research hypothesis is that the test scores will be statistically smaller after exposure to the neutral relative to emotional pictures. Let's run a one-tailed paired-sample Student's t-test:

```{r ttest-within-test}

ttest_within_results <-
  t_test(
    data = ttest_within_data,
    formula = value ~ condition,
    p.adjust.method = "holm",
    paired = TRUE,
    var.equal = TRUE,
    alternative = "less",
    mu = 0,
    conf.level = .95,
    detailed = FALSE
  )

ttest_within_results %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Results indicate that the mean test score is significantly larger in the `emotional` compared to the `neutral` condition: *t*(`r format(ttest_within_results$df, digits = 4)`) = `r format(ttest_within_results$statistic, digits = 3)`, *p* = `r format(ttest_within_results$p, digits = 3)`.

## 2 x 3 mixed ANOVA

Now our hypothetical design gets a bit more complicated. Imagine that, before the online test, we show to participants 50 neutral, 50 pleasant, and 50 unpleasant pictures. Participants are randomly assigned to two groups: one will be administered a drug (N = 30), the other a placebo (N = 40). This is a mixed design. Based on published literature and/or our own data collected as part of previous projects, we expect the following test scores:

* **control** group:
  - **neutral** condition: normal distribution with $\mu$ = 1 and $\sigma$ = 1
  - **unpleasant** condition: normal distribution with $\mu$ = 1.5 and $\sigma$ = 1.2
  - **pleasant** condition: normal distribution with $\mu$ = 1.4 and $\sigma$ = 1.2
* **drug** group:
  - **neutral** condition: normal distribution with $\mu$ = 1.1 and $\sigma$ = 1.2
  - **unpleasant** condition: normal distribution with $\mu$ = 1.4 and $\sigma$ = 1.5
  - **pleasant** condition: normal distribution with $\mu$ = 2.1 and $\sigma$ = 1.6

Create the variables:

```{r ANOVA-params}

ANOVA_within <- list(condition = c("neutral", "unpleasant", "pleasant"))
ANOVA_between <- list(treatment = c("control", "drug"))
ANOVA_n <- list(
  control = c(neutral = 40, unpleasant = 40, pleasant = 40), # number of participants must be the same for each condition...
  drug = c(neutral = 30, unpleasant = 30, pleasant = 30) # ... but can be different between groups
)
ANOVA_mu_cond <- list(
  control = c(neutral = 1, unpleasant = 1.5, pleasant = 1.4),
  drug = c(neutral = 1.1, unpleasant = 1.4, pleasant = 2.1)
)
ANOVA_sd_cond <- list(
  control = c(neutral = 1, unpleasant = 1.2, pleasant = 1.2),
  drug = c(neutral = 1.2, unpleasant = 1.5, pleasant = 1.6)
)

ANOVA_r <- list( # if the design has more than 2 within-subject conditions, specify each correlation in the upper right triangle of the correlation matrix as a vector (https://debruine.github.io/faux/articles/sim_design.html#correlations-1)
  control = c(
    .40, .50,
    .60
  ),
  drug = c(
    .15, .25,
    .45
  )
)

```

Simulate data:

```{r ANOVA-data}

ANOVA_data <-
  sim_design(
    within = ANOVA_within,
    between = ANOVA_between,
    n = ANOVA_n,
    mu = ANOVA_mu_cond,
    sd = ANOVA_sd_cond,
    r = ANOVA_r,
    empirical = FALSE,
    long = TRUE,
    dv = list(value = "value"),
    id = list(id = "id"),
    plot = FALSE,
    rep = 1
  ) %>%
  as_tibble()

```

Look at the first 10 rows of the simulated dataset:

```{r ANOVA-data-show}

# show first 10 rows
ANOVA_data %>%
  head(n = 10) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Save the data:

```{r ANOVA-data-save}

write_csv(
  ANOVA_data,
  here("data/ANOVA_data.csv")
)

```

Plot:

```{r ANOVA-plot}

ANOVA_plot <-
  ANOVA_data %>%
  plot_design(geoms = c("box", "violin", "jitter")) +
  ggtitle("Mixed ANOVA") +
  theme_custom +
  theme(legend.position = "right")

ANOVA_plot

```

Save the plot:

```{r ANOVA-plot-save}

ggsave(
  filename = "ANOVA_plot.png",
  plot = ANOVA_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

```

### Parameter recovery

Verify that `faux` correctly sampled from the normal distributions indicated above:

```{r ANOVA-param-recovery}

ANOVA_param_recovery <-
  ANOVA_data %>%
  group_by(treatment, condition) %>% 
  get_summary_stats(
    type = "mean_sd"
  ) %>% 
  ungroup() %>% 
  mutate(
    mean_imputed = c(map_chr(ANOVA_mu_cond$control, toString), map_chr(ANOVA_mu_cond$drug, toString)),
    sd_imputed = c(map_chr(ANOVA_sd_cond$control, toString), map_chr(ANOVA_sd_cond$drug, toString))
  ) %>% 
  select(variable, condition, n, mean, mean_imputed, sd, sd_imputed)

ANOVA_param_recovery %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Looks ok.

### Statistical Analysis

Let's run a mixed ANOVA on the simulated data. First, the omnibus test:

```{r ANOVA-test-omnibus}

ANOVA_omnibus <-
  anova_test(
    data = ANOVA_data,
    dv = value,
    wid = id,
    between = "treatment",
    within = "condition",
    type = 2,
    effect.size = "ges",
    detailed = FALSE
  ) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "holm")

ANOVA_omnibus

```

Results show a statistically significant main effect of `condition` (*F*(`r format(ANOVA_omnibus$DFn[2])`, `r format(ANOVA_omnibus$DFd[2])`) = `r format(ANOVA_omnibus$F[2])`, *p* = `r format(ANOVA_omnibus$p.adj[2])`, $\eta_{G}^{2}$ = `r format(ANOVA_omnibus$ges[2], digits = 3)`) and `treatment` x `condition` (*F*(`r format(ANOVA_omnibus$DFn[3])`, `r format(ANOVA_omnibus$DFd[3])`) = `r format(ANOVA_omnibus$F[3])`, *p* = `r format(ANOVA_omnibus$p.adj[3])`, $\eta_{G}^{2}$ = `r format(ANOVA_omnibus$ges[3], digits = 3)`).

Do the scores of our online test differ as a function of group?

```{r ANOVA-test-treatment}

ANOVA_pairwise_treatment <-
  ANOVA_data %>%
  group_by(condition) %>%
  t_test(
    formula = value ~ treatment,
    p.adjust.method = "holm",
    paired = FALSE,
    var.equal = TRUE,
    alternative = "two.sided",
    mu = 0,
    conf.level = 0.95
  )

ANOVA_pairwise_treatment

```

Pairwise comparisons suggest that test scores in the `drug` group are statistically larger than in the `control` group only in the `pleasant` condition: *t*(`r format(ANOVA_pairwise_treatment$df[3])`) = `r format(ANOVA_pairwise_treatment$statistic[3])`, *p* = `r format(ANOVA_pairwise_treatment$p[3])`.

```{r ANOVA-test-conditio}

ANOVA_pairwise_condition <-
  ANOVA_data %>%
  group_by(treatment) %>%
  t_test(
    formula = value ~ condition,
    p.adjust.method = "holm",
    paired = TRUE,
    var.equal = TRUE,
    alternative = "two.sided",
    mu = 0,
    conf.level = 0.95
  )

ANOVA_pairwise_condition

```

Within each group, differences among `condition` levels are only observed in the `drug` group, with statistically larger scores in the `pleasant` compared to the `neutral` condition: *t*(`r format(ANOVA_pairwise_condition$df[5])`) = `r format(ANOVA_pairwise_condition$statistic[5], digits = 3)`, *p* = `r format(ANOVA_pairwise_condition$p[5])`.




















## Multilevel Model

### Data Simulation

`sim_mixed_cc` would not allow you to specify random slopes


From https://debruine.github.io/lmem_sim/articles/appendix1a_example_code.html





```{r MLM-params}

# parameters
MLM_n_ssj <- 50 # number of participants
# condition labels
MLM_cat_cond1 <- "ingroup"
MLM_cat_cond2 <- "outgroup"
# number of items for each condition
MLM_n_trials_cond1 <- 25
MLM_n_trials_cond2 <- 25
MLM_mu_grand <- 800 # grand mean [beta_0]
MLM_cond_beta <- 50 # effect of condition [beta_1]
MLM_item_sd <- 80 # by-item random intercept sd [omega_0]
MLM_ssj_sd <- 100 # by-subject random intercept sd [tau_0]
MLM_ssjslope_sd <- 40 # by-subject random slope sd [tau_1]
MLM_cor_int_slope <- .2 # correlation between intercept and slope [rho]
MLM_error_sd <- 200 # residual (standard deviation) [sigma]

```

```{r MLM-data-fun}

# custom data simulation function
MLM_data_fun <- function(
                         n_subj = MLM_n_ssj, # number of subjects
                         label_cond1 = MLM_cat_cond1, # label condition 1
                         label_cond2 = MLM_cat_cond2, # label condition 2
                         n_cond1 = MLM_n_trials_cond1, # number of stimuli condition 1
                         n_cond2 = MLM_n_trials_cond2, # number of stimuli condition 2
                         beta_0 = MLM_mu_grand, # grand mean
                         beta_1 = MLM_cond_beta, # effect of category
                         omega_0 = MLM_item_sd, # by-item random intercept sd
                         tau_0 = MLM_ssj_sd, # by-subject random intercept sd
                         tau_1 = MLM_ssjslope_sd, # by-subject random slope sd
                         rho = MLM_cor_int_slope, # correlation between intercept and slope
                         sigma = MLM_error_sd) { # residual (standard deviation)

  # simulate a sample of items
  items <- data.frame(
    item_id = seq_len(n_cond1 + n_cond2),
    condition = rep(c(label_cond1, label_cond2), c(n_cond1, n_cond2)),
    X_i = rep(c(-0.5, 0.5), c(n_cond1, n_cond2)),
    O_0i = rnorm(n = n_cond1 + n_cond2, mean = 0, sd = omega_0)
  )

  # simulate a sample of subjects
  subjects <- faux::rnorm_multi(
    n = n_subj, mu = 0, sd = c(tau_0, tau_1), r = rho,
    varnames = c("T_0s", "T_1s")
  )
  subjects$subj_id <- 1:n_subj

  # cross subject and item IDs
  crossing(subjects, items) %>%
    mutate(
      e_si = rnorm(nrow(.), mean = 0, sd = sigma),
      value = beta_0 + T_0s + O_0i + (beta_1 + T_1s) * X_i + e_si
    ) %>%
    select(subj_id, item_id, condition, X_i, value) %>%
    arrange(subj_id)
}

```

```{r MLM-data}

MLM_data <- MLM_data_fun()

# save as .csv
write_csv(
  MLM_data,
  here("data/MLM_data.csv")
)

# show first 10 rows
MLM_data %>%
  head(n = 10) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

### Statistical Analysis

```{r MLM-test}

# fit a linear mixed-effects model to data
MLM_results <- lmer(value ~ 1 + X_i + (1 | item_id) + (1 + X_i | subj_id),
  data = MLM_data
)

tibble(
  variable = c(
    "beta_0",
    "beta_1",
    "tau_0",
    "rho",
    "tau_1",
    "omega_0",
    "sigma"
  ),
  explanation = c(
    "intercept (grand mean)",
    "fixed effect of category",
    "by-item random intercept SD",
    "by-subject random intercept SD",
    "correlation between intercept and slope",
    "by-subject random slope SD",
    "residual (error) SD"
  ),
  `simulated value` = c(
    MLM_mu_grand,
    MLM_cond_beta,
    MLM_item_sd,
    MLM_ssj_sd,
    MLM_cor_int_slope,
    MLM_ssjslope_sd,
    MLM_error_sd
  ),
  `estimated by model` = broom.mixed::tidy(MLM_results)$estimate
) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

### Graph

```{r MLM-plot}

MLM_plot <-
  ggviolin(
    MLM_data, # data
    x = "condition", # independent variable
    y = "value", # dependent variable
    color = "condition", # density: line color
    size = 1, # density: line width
    fill = "condition", # density: fill color
    alpha = .5, # density: fill color transparency
    linetype = "solid", # density: line type
    palette = c("#00AFBB", "#E7B800"), # density: color palette
    trim = TRUE, # density: trim tails
    width = 1, # density: violin width
    add = c("boxplot", "jitter"), # overlay boxplot and jittered individual data points
    add.params = list(
      color = "black", # boxplot and jittered points: color
      fill = "white",# boxplot and jittered points: fill color
      alpha = .2# boxplot and jittered points: fill transparency
    ),
    title = "Multilevel Model", # plot title
    label.rectangle = TRUE, # rectangle underneath text
    ggtheme = theme_custom # ggplot theme
  )

ggsave(
  filename = "MLM_plot.png",
  plot = MLM_plot,
  device = "png",
  path = here("figures"),
  width = 8,
  height = 8,
  units = "in",
  dpi = 300
)

MLM_plot

```

# Generate data from existing dataset





# Limitations

`faux` only generates samples from normal distributions
better solution: `synthpop`




# Other simulation packages

https://debruine.github.io/faux/index.html

I started this project as a collection of functions I was writing to help with my own work. It’s one of many, many simulation packages in R; here are some others. I haven’t used most of them, so I can’t vouch for them, but if faux doesn’t meet your needs, one of these might.

- simstudy: Simulation of Study Data
- simr: Power Analysis of Generalised Linear Mixed Models by Simulation
- simulator: streamlines the process of performing simulations by creating a common infrastructure that can be easily used and reused across projects
- lsasim: Simulate large scale assessment data
- simmer: Trajectory-based Discrete-Event Simulation (DES)
- parSim: Parallel Simulation Studies







# Session Info

```{r session-info}

sessionInfo()

```

***
***

[^1]: Adapted from the book [**Answering questions with data**](https://crumplab.github.io/statistics/index.html) (Chapter [11](https://crumplab.github.io/statistics/simulating-data.html#reasons-to-simulate)) by Matthew J. C. Crump.
[^2]: I recommend exploring the function `get_summary_stats` from package `rstatix`, especially the argument `type`... it's very comprehensive.
